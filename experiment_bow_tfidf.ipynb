{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LearningBoy2002/Sentiment-Analysis/blob/main/experiment_bow_tfidf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Function to run the experiment\n",
        "def run_experiment(vectorizer_type, ngram_range, vectorizer_max_features, vectorizer_name):\n",
        "    # Step 2: Vectorization\n",
        "    if vectorizer_type == \"BoW\":\n",
        "        vectorizer = CountVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
        "    else:\n",
        "        vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train)\n",
        "    X_test = vectorizer.transform(X_test)\n",
        "\n",
        "    # Step 4: Define and train a Random Forest model\n",
        "    with mlflow.start_run() as run:\n",
        "        # Set tags for the experiment and run\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{vectorizer_name}_{ngram_range}_RandomForest\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"feature_engineering\")\n",
        "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
        "\n",
        "        # Add a description\n",
        "        mlflow.set_tag(\"description\", f\"RandomForest with {vectorizer_name}, ngram_range={ngram_range}, max_features={vectorizer_max_features}\")\n",
        "\n",
        "        # Log vectorizer parameters\n",
        "        mlflow.log_param(\"vectorizer_type\", vectorizer_type)\n",
        "        mlflow.log_param(\"ngram_range\", ngram_range)\n",
        "        mlflow.log_param(\"vectorizer_max_features\", vectorizer_max_features)\n",
        "\n",
        "        # Log Random Forest parameters\n",
        "        n_estimators = 200\n",
        "        max_depth = 15\n",
        "\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "        # Initialize and train the model\n",
        "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Step 5: Make predictions and log metrics\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(f\"Confusion Matrix: {vectorizer_name}, {ngram_range}\")\n",
        "        plt.savefig(\"confusion_matrix.png\")\n",
        "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"random_forest_model_{vectorizer_name}_{ngram_range}\")\n",
        "\n",
        "# Step 6: Run experiments for BoW and TF-IDF with different n-grams\n",
        "ngram_ranges = [(1, 1), (1, 2), (1, 3)]  # unigrams, bigrams, trigrams\n",
        "max_features = 5000  # Example max feature size\n",
        "\n",
        "for ngram_range in ngram_ranges:\n",
        "    # BoW Experiments\n",
        "    run_experiment(\"BoW\", ngram_range, max_features, vectorizer_name=\"BoW\")\n",
        "\n",
        "    # TF-IDF Experiments\n",
        "    run_experiment(\"TF-IDF\", ngram_range, max_features, vectorizer_name=\"TF-IDF\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83eb98f-56a5-44fe-8a1f-4f2c5b6d8c5a",
        "id": "1VSxQo0YO15n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:52:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run BoW_(1, 1)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/d5e7bc21c15541c9b6792f65f13995fc\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:52:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run TF-IDF_(1, 1)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/fe6fcd8aa33a4ab0b328df541c71db90\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:53:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run BoW_(1, 2)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/b6bba7841dde45ae9234e7f62a9c3532\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:54:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run TF-IDF_(1, 2)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/96d11a6c082645ea825b13d0151d4746\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:54:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run BoW_(1, 3)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/8b91d298a2d64270a6826196f4451e09\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:55:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run TF-IDF_(1, 3)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/772d81b300444c90a85906fcf8ee5153\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Function to run the experiment\n",
        "def run_experiment(vectorizer_type, ngram_range, vectorizer_max_features, vectorizer_name):\n",
        "    # Step 2: Vectorization\n",
        "    if vectorizer_type == \"BoW\":\n",
        "        vectorizer = CountVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
        "    else:\n",
        "        vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train)\n",
        "    X_test = vectorizer.transform(X_test)\n",
        "\n",
        "    # Step 4: Define and train a Random Forest model\n",
        "    with mlflow.start_run() as run:\n",
        "        # Set tags for the experiment and run\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{vectorizer_name}_{ngram_range}_RandomForest\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"feature_engineering\")\n",
        "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
        "\n",
        "        # Add a description\n",
        "        mlflow.set_tag(\"description\", f\"RandomForest with {vectorizer_name}, ngram_range={ngram_range}, max_features={vectorizer_max_features}\")\n",
        "\n",
        "        # Log vectorizer parameters\n",
        "        mlflow.log_param(\"vectorizer_type\", vectorizer_type)\n",
        "        mlflow.log_param(\"ngram_range\", ngram_range)\n",
        "        mlflow.log_param(\"vectorizer_max_features\", vectorizer_max_features)\n",
        "\n",
        "        # Log Random Forest parameters\n",
        "        n_estimators = 200\n",
        "        max_depth = 15\n",
        "\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "        # Initialize and train the model\n",
        "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Step 5: Make predictions and log metrics\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(f\"Confusion Matrix: {vectorizer_name}, {ngram_range}\")\n",
        "        plt.savefig(\"confusion_matrix.png\")\n",
        "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"random_forest_model_{vectorizer_name}_{ngram_range}\")\n",
        "\n",
        "# Step 6: Run experiments for BoW and TF-IDF with different n-grams\n",
        "ngram_ranges = [(1, 1), (1, 2), (1, 3)]  # unigrams, bigrams, trigrams\n",
        "max_features = 5000  # Example max feature size\n",
        "\n",
        "for ngram_range in ngram_ranges:\n",
        "    # BoW Experiments\n",
        "    run_experiment(\"BoW\", ngram_range, max_features, vectorizer_name=\"BoW\")\n",
        "\n",
        "    # TF-IDF Experiments\n",
        "    run_experiment(\"TF-IDF\", ngram_range, max_features, vectorizer_name=\"TF-IDF\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83eb98f-56a5-44fe-8a1f-4f2c5b6d8c5a",
        "id": "lIiDejCjO21P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:52:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run BoW_(1, 1)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/d5e7bc21c15541c9b6792f65f13995fc\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:52:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run TF-IDF_(1, 1)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/fe6fcd8aa33a4ab0b328df541c71db90\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:53:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run BoW_(1, 2)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/b6bba7841dde45ae9234e7f62a9c3532\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:54:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run TF-IDF_(1, 2)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/96d11a6c082645ea825b13d0151d4746\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:54:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run BoW_(1, 3)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/8b91d298a2d64270a6826196f4451e09\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:55:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run TF-IDF_(1, 3)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/772d81b300444c90a85906fcf8ee5153\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Function to run the experiment\n",
        "def run_experiment(vectorizer_type, ngram_range, vectorizer_max_features, vectorizer_name):\n",
        "    # Step 2: Vectorization\n",
        "    if vectorizer_type == \"BoW\":\n",
        "        vectorizer = CountVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
        "    else:\n",
        "        vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train)\n",
        "    X_test = vectorizer.transform(X_test)\n",
        "\n",
        "    # Step 4: Define and train a Random Forest model\n",
        "    with mlflow.start_run() as run:\n",
        "        # Set tags for the experiment and run\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{vectorizer_name}_{ngram_range}_RandomForest\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"feature_engineering\")\n",
        "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
        "\n",
        "        # Add a description\n",
        "        mlflow.set_tag(\"description\", f\"RandomForest with {vectorizer_name}, ngram_range={ngram_range}, max_features={vectorizer_max_features}\")\n",
        "\n",
        "        # Log vectorizer parameters\n",
        "        mlflow.log_param(\"vectorizer_type\", vectorizer_type)\n",
        "        mlflow.log_param(\"ngram_range\", ngram_range)\n",
        "        mlflow.log_param(\"vectorizer_max_features\", vectorizer_max_features)\n",
        "\n",
        "        # Log Random Forest parameters\n",
        "        n_estimators = 200\n",
        "        max_depth = 15\n",
        "\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "        # Initialize and train the model\n",
        "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Step 5: Make predictions and log metrics\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(f\"Confusion Matrix: {vectorizer_name}, {ngram_range}\")\n",
        "        plt.savefig(\"confusion_matrix.png\")\n",
        "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"random_forest_model_{vectorizer_name}_{ngram_range}\")\n",
        "\n",
        "# Step 6: Run experiments for BoW and TF-IDF with different n-grams\n",
        "ngram_ranges = [(1, 1), (1, 2), (1, 3)]  # unigrams, bigrams, trigrams\n",
        "max_features = 5000  # Example max feature size\n",
        "\n",
        "for ngram_range in ngram_ranges:\n",
        "    # BoW Experiments\n",
        "    run_experiment(\"BoW\", ngram_range, max_features, vectorizer_name=\"BoW\")\n",
        "\n",
        "    # TF-IDF Experiments\n",
        "    run_experiment(\"TF-IDF\", ngram_range, max_features, vectorizer_name=\"TF-IDF\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83eb98f-56a5-44fe-8a1f-4f2c5b6d8c5a",
        "id": "gU2gUN4JO3FX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:52:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run BoW_(1, 1)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/d5e7bc21c15541c9b6792f65f13995fc\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:52:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run TF-IDF_(1, 1)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/fe6fcd8aa33a4ab0b328df541c71db90\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:53:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run BoW_(1, 2)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/b6bba7841dde45ae9234e7f62a9c3532\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:54:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run TF-IDF_(1, 2)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/96d11a6c082645ea825b13d0151d4746\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:54:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run BoW_(1, 3)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/8b91d298a2d64270a6826196f4451e09\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:55:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run TF-IDF_(1, 3)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/772d81b300444c90a85906fcf8ee5153\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xWtxlBuhCrYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which vectorization?"
      ],
      "metadata": {
        "id": "fz2DOoos_1KQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI2g8hNmkYBL",
        "outputId": "83eb6cb6-9c0c-4c5a-c5e1-140212697617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.21.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.37.17-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.38.17-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mlflow-skinny==2.21.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.21.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.14.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.39)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.21.0->mlflow)\n",
            "  Downloading databricks_sdk-0.46.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting fastapi<1 (from mlflow-skinny==2.21.0->mlflow)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (1.31.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (5.29.3)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (2.10.6)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (4.12.2)\n",
            "Collecting uvicorn<1 (from mlflow-skinny==2.21.0->mlflow)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting botocore<1.38.0,>=1.37.17 (from boto3)\n",
            "  Downloading botocore-1.37.17-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3)\n",
            "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting docutils<0.17,>=0.10 (from awscli)\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting colorama<0.4.7,>=0.2.5 (from awscli)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.17->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.17->boto3) (2.3.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow) (2.38.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.21.0->mlflow)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.21.0->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.0->mlflow) (1.2.18)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.0->mlflow) (0.52b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.0->mlflow) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.17->boto3) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.0->mlflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.0->mlflow) (2025.1.31)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.21.0->mlflow) (0.14.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.0->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.0->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.0->mlflow) (1.3.1)\n",
            "Downloading mlflow-2.21.0-py3-none-any.whl (28.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.21.0-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.37.17-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading awscli-1.38.17-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.37.17-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.46.0-py3-none-any.whl (677 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m677.5/677.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, rsa, jmespath, gunicorn, graphql-core, docutils, colorama, starlette, graphql-relay, docker, botocore, alembic, s3transfer, graphene, fastapi, databricks-sdk, boto3, awscli, mlflow-skinny, mlflow\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.21.2\n",
            "    Uninstalling docutils-0.21.2:\n",
            "      Successfully uninstalled docutils-0.21.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sphinx 8.2.3 requires docutils<0.22,>=0.20, but you have docutils 0.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.15.1 awscli-1.38.17 boto3-1.37.17 botocore-1.37.17 colorama-0.4.6 databricks-sdk-0.46.0 docker-7.1.0 docutils-0.16 fastapi-0.115.11 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 jmespath-1.0.1 mlflow-2.21.0 mlflow-skinny-2.21.0 rsa-4.7.2 s3transfer-0.11.4 starlette-0.46.1 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow boto3 awscli"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!aws configure"
      ],
      "metadata": {
        "id": "YBV7kuUAgNIK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "# Step 2: Set up the MLflow tracking server\n",
        "mlflow.set_tracking_uri(\"http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/\")"
      ],
      "metadata": {
        "id": "DmfxCCFNlO3Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"Exp 2 - BoW vs TfIdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zan6jEqglYPS",
        "outputId": "4d9fc374-0eb3-4382-b6ea-e5e9f4a51e4b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/03/20 19:47:22 INFO mlflow.tracking.fluent: Experiment with name 'Exp 2 - BoW vs TfIdf' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://bishwarup-sentiment-analysis-1/214129867652901956', creation_time=1742500042442, experiment_id='214129867652901956', last_update_time=1742500042442, lifecycle_stage='active', name='Exp 2 - BoW vs TfIdf', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import mlflow.sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "4B6s4MsqlveI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuHBlkE4G2NI",
        "outputId": "acbfcf28-3183-412e-b7e5-f906c57e467f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Projects/Reddit Sentiment analysis/reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvkWQ-SYl0rY",
        "outputId": "890d95fe-dada-47be-d41d-2e055c41fa0b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36662, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Function to run the experiment\n",
        "def run_experiment(vectorizer_type, ngram_range, vectorizer_max_features, vectorizer_name):\n",
        "    # Step 2: Vectorization\n",
        "    if vectorizer_type == \"BoW\":\n",
        "        vectorizer = CountVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
        "    else:\n",
        "        vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train)\n",
        "    X_test = vectorizer.transform(X_test)\n",
        "\n",
        "    # Step 4: Define and train a Random Forest model\n",
        "    with mlflow.start_run() as run:\n",
        "        # Set tags for the experiment and run\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{vectorizer_name}_{ngram_range}_RandomForest\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"feature_engineering\")\n",
        "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
        "\n",
        "        # Add a description\n",
        "        mlflow.set_tag(\"description\", f\"RandomForest with {vectorizer_name}, ngram_range={ngram_range}, max_features={vectorizer_max_features}\")\n",
        "\n",
        "        # Log vectorizer parameters\n",
        "        mlflow.log_param(\"vectorizer_type\", vectorizer_type)\n",
        "        mlflow.log_param(\"ngram_range\", ngram_range)\n",
        "        mlflow.log_param(\"vectorizer_max_features\", vectorizer_max_features)\n",
        "\n",
        "        # Log Random Forest parameters\n",
        "        n_estimators = 200\n",
        "        max_depth = 15\n",
        "\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "        # Initialize and train the model\n",
        "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Step 5: Make predictions and log metrics\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(f\"Confusion Matrix: {vectorizer_name}, {ngram_range}\")\n",
        "        plt.savefig(\"confusion_matrix.png\")\n",
        "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"random_forest_model_{vectorizer_name}_{ngram_range}\")\n",
        "\n",
        "# Step 6: Run experiments for BoW and TF-IDF with different n-grams\n",
        "ngram_ranges = [(1, 1), (1, 2), (1, 3)]  # unigrams, bigrams, trigrams\n",
        "max_features = 5000  # Example max feature size\n",
        "\n",
        "for ngram_range in ngram_ranges:\n",
        "    # BoW Experiments\n",
        "    run_experiment(\"BoW\", ngram_range, max_features, vectorizer_name=\"BoW\")\n",
        "\n",
        "    # TF-IDF Experiments\n",
        "    run_experiment(\"TF-IDF\", ngram_range, max_features, vectorizer_name=\"TF-IDF\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RejOAvqgkwM0",
        "outputId": "c83eb98f-56a5-44fe-8a1f-4f2c5b6d8c5a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:52:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run BoW_(1, 1)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/d5e7bc21c15541c9b6792f65f13995fc\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:52:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run TF-IDF_(1, 1)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/fe6fcd8aa33a4ab0b328df541c71db90\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:53:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run BoW_(1, 2)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/b6bba7841dde45ae9234e7f62a9c3532\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:54:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run TF-IDF_(1, 2)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/96d11a6c082645ea825b13d0151d4746\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:54:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run BoW_(1, 3)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/8b91d298a2d64270a6826196f4451e09\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/20 19:55:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run TF-IDF_(1, 3)_RandomForest at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956/runs/772d81b300444c90a85906fcf8ee5153\n",
            "üß™ View experiment at: http://ec2-13-126-76-147.ap-south-1.compute.amazonaws.com:5000/#/experiments/214129867652901956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zH0Sxuf2GxNa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pTtQw8F1lgBB"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}